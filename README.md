# ğŸ¯ Digikala Customer Churn Prediction

End-to-end ML pipeline for predicting customer churn.

Ù¾Ø§ÛŒÙ¾Ù„Ø§ÛŒÙ† Ú©Ø§Ù…Ù„ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÛŒØ²Ø´ Ù…Ø´ØªØ±ÛŒØ§Ù†

---

## ğŸ“Š Results Summary

| Metric | Value |
|--------|-------|
| **ROC-AUC** | 0.879 |
| **F1-Score** | 0.849 |
| **Churn Rate** | 65% |
| **Users** | 338,101 |
| **Features** | 26 |

---

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- Python 3.10+ (for running notebooks)

### 1. Clone & Setup

```bash
git clone https://github.com/peyman886/digikala-customer-churn-prediction.git
cd digikala-customer-churn-prediction

# Copy environment file
cp .env.example .env
```

### 2. Add Data Files

Download data from Google Drive and place in `data/` folder:
- `data/orders.csv`
- `data/crm.csv`
- `data/order_comments.csv`

### 3. Start Database

```bash
docker-compose up -d db
# Wait for database to be ready (~10 seconds)
```

### 4. Load Data

```bash
python db/load_data.py
```

### 5. Run Notebooks (Train Model)

```bash
# Option A: Using Jupyter in Docker
docker-compose --profile dev up -d jupyter
# Open http://localhost:8888 (token: churn123)

# Option B: Local Jupyter
pip install -r requirements.txt
jupyter notebook notebooks/
```

Run notebooks in order:
1. `01_eda_feature_engineering.ipynb` â†’ generates `user_features.csv`
2. `02_model_training.ipynb` â†’ generates `model.pkl`

### 6. Start API

```bash
docker-compose up -d api
```

### 7. Test API

```bash
# Health check
curl http://localhost:8000/health

# Predict churn
curl -X POST http://localhost:8000/predict \
     -H "Content-Type: application/json" \
     -d '{"user_id": "1385028"}'
```

**Example Response:**
```json
{
  "user_id": "1385028",
  "will_churn": true,
  "probability": 0.8234,
  "risk_level": "HIGH"
}
```

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ data/                       # Data files (not in git)
â”‚   â”œâ”€â”€ orders.csv
â”‚   â”œâ”€â”€ crm.csv
â”‚   â”œâ”€â”€ order_comments.csv
â”‚   â””â”€â”€ user_features.csv       # Generated by notebook
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 00_schema_design_eda.ipynb
â”‚   â”œâ”€â”€ 01_eda_feature_engineering.ipynb
â”‚   â””â”€â”€ 02_model_training.ipynb
â”‚
â”œâ”€â”€ app/                        # FastAPI application
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ model.pkl               # Trained model
â”‚   â”œâ”€â”€ user_features.csv       # For predictions
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ schema.sql              # PostgreSQL schema
â”‚   â””â”€â”€ load_data.py            # Data loading script
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ test_api.py             # API test script
â”‚
â”œâ”€â”€ reports/                    # Generated plots
â”‚   â”œâ”€â”€ model_comparison.png
â”‚   â”œâ”€â”€ feature_importance.png
â”‚   â””â”€â”€ confusion_matrix.png
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ¯ Churn Definition

A user is **churned** if they have **no orders in the 30 days** following the observation date.

```
Data Timeline:
â”œâ”€â”€ Mar 16 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Aug 13 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Sep 12
â”‚   Features calculated from this period   â”‚   Label period    â”‚
â”‚   (150 days of history)                  â”‚   (30 days)       â”‚
```

**Key:** Features only use data BEFORE observation date â†’ **No data leakage**

---

## ğŸ“ˆ Features (26 total)

| Category | Features |
|----------|----------|
| **Temporal** | total_orders, days_since_last_order, avg_order_gap, orders_last_30d, orders_last_7d |
| **Delivery** | on_time_ratio, late_delivery_count, unknown_otd_ratio |
| **CRM** | total_complaints, fake_complaints, complaints_per_order |
| **Ratings** | avg_shop_rating, avg_courier_rating, min_ratings, has_low_rating |
| **Comments** | comment_count, comment_ratio, avg_comment_length |

### Top 5 Predictive Features
1. `days_since_last_order` - Recency is king!
2. `orders_last_30d` - Recent activity
3. `orders_last_7d` - Very recent activity
4. `total_orders` - Engagement level
5. `avg_order_gap_days` - Purchase frequency

---

## ğŸ—„ï¸ Database Schema

```sql
-- Main table
orders (order_id PK, user_id, is_otd, order_date, delivery_status)

-- 1:1 with orders
crm (order_id PK/FK, delivery_request_count, fake_request_count, rate_to_shop, rate_to_courier)

-- 1:N with orders  
comments (id PK, order_id FK, description)
```

---

## ğŸ”Œ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | API info |
| GET | `/health` | Health check |
| GET | `/docs` | Swagger UI |
| POST | `/predict` | Predict churn |

### POST /predict

**Request:**
```json
{"user_id": "1385028"}
```

**Response:**
```json
{
  "user_id": "1385028",
  "will_churn": true,
  "probability": 0.8234,
  "risk_level": "HIGH"
}
```

**Risk Levels:**
- `HIGH`: probability â‰¥ 0.7
- `MEDIUM`: 0.4 â‰¤ probability < 0.7
- `LOW`: probability < 0.4

---

## ğŸ³ Docker Commands

```bash
# Start all services
docker-compose up -d

# Start only database
docker-compose up -d db

# Start with development tools (Jupyter + PgAdmin)
docker-compose --profile dev up -d

# View logs
docker-compose logs -f api

# Stop all
docker-compose down

# Stop and remove volumes (fresh start)
docker-compose down -v
```

---

## ğŸ”§ Development

### Local Setup (without Docker)

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or: venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Run API locally
cd app
uvicorn main:app --reload

# Run tests
python scripts/test_api.py
```

---

## ğŸ“ Assumptions & Decisions

1. **Churn Window:** 30 days (industry standard for e-commerce)
2. **is_otd = -1:** Treated as "unknown", excluded from on_time_ratio calculation
3. **Orphan Comments:** 5,037 comments without matching orders â†’ filtered during load
4. **Missing Ratings:** ~60-74% NULL â†’ filled with median (neutral value)
5. **Model Choice:** XGBoost (best ROC-AUC among 4 tested models)

---

## ğŸš§ Future Improvements

- [ ] Add model versioning (MLflow)
- [ ] Time-based train/test split (more realistic)
- [ ] Sentiment analysis on Persian comments
- [ ] Real-time feature computation
- [ ] A/B testing framework
- [ ] Monitoring dashboard (Grafana)
- [ ] Automated retraining pipeline

---

## ğŸ‘¤ Author

**Peyman**  
GitHub: [@peyman886](https://github.com/peyman886)

---

## ğŸ“„ License

MIT License