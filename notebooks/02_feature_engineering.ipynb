{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”§ Feature Engineering for Churn Prediction\n",
    "\n",
    "This notebook creates user-level features from orders, CRM, and comments data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from textblob import TextBlob\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "load_dotenv()\n",
    "print('âœ… Libraries imported successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Load Data from Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection\n",
    "DB_URL = os.getenv('DATABASE_URL', 'postgresql://ds_user:ds_pass@localhost:5432/churn_db')\n",
    "engine = create_engine(DB_URL)\n",
    "\n",
    "# Load data\n",
    "orders_df = pd.read_sql(\"SELECT * FROM orders\", engine)\n",
    "crm_df = pd.read_sql(\"SELECT * FROM crm\", engine)\n",
    "comments_df = pd.read_sql(\"SELECT * FROM comments\", engine)\n",
    "\n",
    "print(f\"ğŸ“Š Data loaded:\")\n",
    "print(f\"  - Orders: {len(orders_df):,} rows\")\n",
    "print(f\"  - CRM: {len(crm_df):,} rows\")\n",
    "print(f\"  - Comments: {len(comments_df):,} rows\")\n",
    "print(f\"  - Unique users: {orders_df['user_id'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on order_id\n",
    "merged_df = orders_df.merge(crm_df, on='order_id', how='left')\n",
    "merged_df = merged_df.merge(comments_df, on='order_id', how='left')\n",
    "\n",
    "# Convert dates\n",
    "merged_df['order_date'] = pd.to_datetime(merged_df['order_date'])\n",
    "\n",
    "# Reference date (last date in dataset)\n",
    "reference_date = merged_df['order_date'].max()\n",
    "print(f\"ğŸ“… Reference date: {reference_date}\")\n",
    "print(f\"ğŸ“Š Merged data shape: {merged_df.shape}\")\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Feature Engineering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_features(df: pd.DataFrame, reference_date: pd.Timestamp) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create comprehensive user-level features for churn prediction.\n",
    "    \n",
    "    Args:\n",
    "        df: Merged dataframe with orders, CRM, and comments\n",
    "        reference_date: Date to use as reference for recency calculations\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with user-level features and churn label\n",
    "    \"\"\"\n",
    "    user_features = []\n",
    "    \n",
    "    for user_id, user_data in df.groupby('user_id'):\n",
    "        user_orders = user_data.sort_values('order_date')\n",
    "        \n",
    "        # ========== TEMPORAL FEATURES ==========\n",
    "        last_order_date = user_orders['order_date'].max()\n",
    "        first_order_date = user_orders['order_date'].min()\n",
    "        days_since_last_order = (reference_date - last_order_date).days\n",
    "        days_since_first_order = (reference_date - first_order_date).days\n",
    "        \n",
    "        # ========== ORDER BEHAVIOR FEATURES ==========\n",
    "        total_orders = len(user_orders)\n",
    "        avg_order_frequency = days_since_first_order / max(total_orders - 1, 1)\n",
    "        \n",
    "        # Order recency trend (recent vs old behavior)\n",
    "        recent_orders = len(user_orders[user_orders['order_date'] > (reference_date - timedelta(days=30))])\n",
    "        recent_order_ratio = recent_orders / total_orders if total_orders > 0 else 0\n",
    "        \n",
    "        # ========== DELIVERY PERFORMANCE ==========\n",
    "        on_time_orders = user_orders['is_otd'].sum()\n",
    "        on_time_ratio = on_time_orders / total_orders if total_orders > 0 else 0\n",
    "        late_delivery_count = total_orders - on_time_orders\n",
    "        \n",
    "        # ========== CRM FEATURES ==========\n",
    "        total_complaints = user_orders['crm_delivery_request_count'].sum()\n",
    "        total_fake_complaints = user_orders['crm_fake_delivery_request_count'].sum()\n",
    "        complaints_per_order = total_complaints / total_orders if total_orders > 0 else 0\n",
    "        fake_complaint_ratio = total_fake_complaints / max(total_complaints, 1)\n",
    "        \n",
    "        # Average ratings\n",
    "        avg_shop_rating = user_orders['rate_to_shop'].mean()\n",
    "        avg_courier_rating = user_orders['rate_to_courier'].mean()\n",
    "        min_shop_rating = user_orders['rate_to_shop'].min()\n",
    "        min_courier_rating = user_orders['rate_to_courier'].min()\n",
    "        \n",
    "        # ========== SENTIMENT ANALYSIS ==========\n",
    "        comments = user_orders['description'].dropna()\n",
    "        if len(comments) > 0:\n",
    "            sentiments = [TextBlob(str(comment)).sentiment.polarity for comment in comments]\n",
    "            avg_sentiment = np.mean(sentiments)\n",
    "            min_sentiment = np.min(sentiments)\n",
    "            max_sentiment = np.max(sentiments)\n",
    "            sentiment_std = np.std(sentiments)\n",
    "            negative_comment_count = sum(1 for s in sentiments if s < -0.1)\n",
    "        else:\n",
    "            avg_sentiment = 0\n",
    "            min_sentiment = 0\n",
    "            max_sentiment = 0\n",
    "            sentiment_std = 0\n",
    "            negative_comment_count = 0\n",
    "        \n",
    "        # ========== CHURN LABEL ==========\n",
    "        # User churned if no order in the 30 days after their last order\n",
    "        next_month_end = last_order_date + timedelta(days=30)\n",
    "        future_orders = df[(df['user_id'] == user_id) & \n",
    "                          (df['order_date'] > last_order_date) &\n",
    "                          (df['order_date'] <= next_month_end)]\n",
    "        is_churned = 1 if len(future_orders) == 0 else 0\n",
    "        \n",
    "        user_features.append({\n",
    "            'user_id': user_id,\n",
    "            \n",
    "            # Temporal\n",
    "            'total_orders': total_orders,\n",
    "            'days_since_last_order': days_since_last_order,\n",
    "            'days_since_first_order': days_since_first_order,\n",
    "            'avg_order_frequency': avg_order_frequency,\n",
    "            'recent_order_ratio': recent_order_ratio,\n",
    "            \n",
    "            # Delivery\n",
    "            'on_time_ratio': on_time_ratio,\n",
    "            'late_delivery_count': late_delivery_count,\n",
    "            \n",
    "            # CRM\n",
    "            'total_complaints': total_complaints,\n",
    "            'total_fake_complaints': total_fake_complaints,\n",
    "            'complaints_per_order': complaints_per_order,\n",
    "            'fake_complaint_ratio': fake_complaint_ratio,\n",
    "            'avg_shop_rating': avg_shop_rating,\n",
    "            'avg_courier_rating': avg_courier_rating,\n",
    "            'min_shop_rating': min_shop_rating,\n",
    "            'min_courier_rating': min_courier_rating,\n",
    "            \n",
    "            # Sentiment\n",
    "            'avg_sentiment': avg_sentiment,\n",
    "            'min_sentiment': min_sentiment,\n",
    "            'max_sentiment': max_sentiment,\n",
    "            'sentiment_std': sentiment_std,\n",
    "            'negative_comment_count': negative_comment_count,\n",
    "            \n",
    "            # Target\n",
    "            'is_churned': is_churned\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(user_features)\n",
    "\n",
    "print('âœ… Feature engineering function defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Generate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features (this may take a few minutes)\n",
    "print('â³ Generating features...')\n",
    "user_features_df = create_user_features(merged_df, reference_date)\n",
    "print(f'âœ… Created features for {len(user_features_df):,} users')\n",
    "\n",
    "# Display sample\n",
    "user_features_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "print('ğŸ“Š Missing values before imputation:')\n",
    "print(user_features_df.isnull().sum()[user_features_df.isnull().sum() > 0])\n",
    "\n",
    "# Fill with reasonable defaults\n",
    "user_features_df = user_features_df.fillna({\n",
    "    'avg_shop_rating': 3.0,\n",
    "    'avg_courier_rating': 3.0,\n",
    "    'min_shop_rating': 3.0,\n",
    "    'min_courier_rating': 3.0,\n",
    "    'avg_sentiment': 0.0,\n",
    "    'min_sentiment': 0.0,\n",
    "    'max_sentiment': 0.0,\n",
    "    'sentiment_std': 0.0\n",
    "})\n",
    "\n",
    "print('\\nâœ… Missing values handled')\n",
    "print(f'Remaining nulls: {user_features_df.isnull().sum().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Feature Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn statistics\n",
    "churn_rate = user_features_df['is_churned'].mean()\n",
    "print(f'ğŸ“Š Churn Rate: {churn_rate:.2%}')\n",
    "print(f'   - Churned users: {user_features_df[\"is_churned\"].sum():,}')\n",
    "print(f'   - Active users: {(~user_features_df[\"is_churned\"].astype(bool)).sum():,}')\n",
    "\n",
    "# Feature distributions\n",
    "print('\\nğŸ“Š Feature Summary Statistics:')\n",
    "user_features_df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Feature Correlations with Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with churn\n",
    "feature_cols = [col for col in user_features_df.columns if col not in ['user_id', 'is_churned']]\n",
    "correlations = user_features_df[feature_cols + ['is_churned']].corr()['is_churned'].sort_values(ascending=False)\n",
    "\n",
    "print('ğŸ”— Top 10 Features Correlated with Churn:')\n",
    "print(correlations[1:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ Save Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "output_path = '../data/user_features.csv'\n",
    "user_features_df.to_csv(output_path, index=False)\n",
    "print(f'âœ… Features saved to: {output_path}')\n",
    "print(f'   - Shape: {user_features_df.shape}')\n",
    "print(f'   - File size: {os.path.getsize(output_path) / 1024:.2f} KB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Summary\n",
    "\n",
    "Feature engineering completed successfully! Key achievements:\n",
    "\n",
    "- âœ… Created 20+ user-level features\n",
    "- âœ… Handled missing values appropriately\n",
    "- âœ… Sentiment analysis on comments\n",
    "- âœ… Defined churn label (no order in next 30 days)\n",
    "- âœ… Saved clean dataset for modeling\n",
    "\n",
    "Next step: **Model Training (03_model_training.ipynb)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}