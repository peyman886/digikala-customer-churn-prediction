# =============================================================================
# Churn Prediction API - GPU Dockerfile
# =============================================================================
#
# This Dockerfile builds the API with CUDA-enabled PyTorch.
# Requires NVIDIA GPU and nvidia-docker runtime.
#
# Build:
#   docker build -f Dockerfile.gpu -t churn-api-gpu .
#
# Run:
#   docker run --gpus all -p 8000:8000 \
#       -v /path/to/models_v2:/app/models_v2 \
#       -v /path/to/user_features.csv:/app/user_features.csv \
#       churn-api-gpu
#
# =============================================================================

FROM nvidia/cuda:12.1.0-runtime-ubuntu22.04

WORKDIR /app

# Install Python and system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3.10 \
    python3-pip \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/* \
    && ln -sf /usr/bin/python3.10 /usr/bin/python \
    && ln -sf /usr/bin/pip3 /usr/bin/pip

# Copy requirements first (better caching)
COPY requirements.txt .

# Install PyTorch with CUDA 12.1 support
RUN pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu121

# Install other dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY __init__.py .
COPY config.py .
COPY schemas.py .
COPY services.py .
COPY main.py .
COPY models/ ./models/

# Environment variables
ENV MODEL_DIR=/app/models_v2
ENV FEATURES_PATH=/app/user_features.csv
ENV DEVICE=auto
ENV LOG_LEVEL=INFO

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Run the application
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]